{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\t\t\t resnet101_faster_rcnn_genome_imgfeats\tX-101.lmdb\n",
      "..\t\t\t bua-caffe-r101-fix36\t\t\tannotations\n",
      "X-101\t\t\t README\t\t\t\t\timages\n",
      "flickr30k-images.tar.gz  hard_negative.pkl\n",
      "images.lst\t\t dataset_flickr30k.json\n"
     ]
    }
   ],
   "source": [
    "!ls -f /science/image/nlp-datasets/emanuele/data/flickr30k/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "..\n",
      "193082928_info.npy\n",
      "2214821600_info.npy\n",
      "4841988538.npy\n",
      "5162402452_info.npy\n",
      "4731694958.npy\n",
      "129528391_info.npy\n",
      "4683957629_info.npy\n",
      "2609847254.npy\n",
      "ls: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!ls -f /science/image/nlp-datasets/emanuele/data/flickr30k/X-101 | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "..\n",
      "lock.mdb\n",
      "data.mdb\n"
     ]
    }
   ],
   "source": [
    "!ls -f /science/image/nlp-datasets/emanuele/data/flickr30k/features/flickr30k_X101.lmdb | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".  ..  lock.mdb  data.mdb\n"
     ]
    }
   ],
   "source": [
    "!ls -f /science/image/nlp-datasets/emanuele/data/flickr30k/features/flickr30k_boxes36.lmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmdb\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_path = \"/science/image/nlp-datasets/emanuele/data/flickr30k/features/flickr30k_X101.lmdb\"\n",
    "env = lmdb.open(features_path, max_readers=1, readonly=True, lock=False, readahead=False, meminit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'4841988538', b'4731694958', b'2609847254', b'47321520']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with env.begin(write=False) as txn:\n",
    "    _image_ids = pickle.loads(txn.get(\"keys\".encode()))\n",
    "_image_ids[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "image_id = _image_ids[index]\n",
    "with env.begin(write=False) as txn:\n",
    "    item = pickle.loads(txn.get(image_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['feature_path', 'features', 'image_height', 'image_width', 'num_boxes', 'objects', 'cls_prob', 'bbox'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4841988538'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item['feature_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 99.64347,  68.05333, 193.47815, 133.9668 ], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item['bbox'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.3864238 , 0.        , 0.        , ..., 0.        , 3.7216337 ,\n",
       "        2.0170946 ],\n",
       "       [0.        , 1.4387386 , 0.        , ..., 1.9447222 , 0.        ,\n",
       "        0.        ],\n",
       "       [2.4254103 , 0.90743715, 0.        , ..., 0.46917439, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [1.2574073 , 0.3921312 , 0.        , ..., 0.7907711 , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.2256733 , 0.2729268 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 1.6976906 , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item['features'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.3864238 , 0.        , 0.        , ..., 0.        , 3.7216337 ,\n",
       "        2.0170946 ],\n",
       "       [0.        , 1.4387386 , 0.        , ..., 1.9447222 , 0.        ,\n",
       "        0.        ],\n",
       "       [2.4254103 , 0.90743715, 0.        , ..., 0.46917439, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [1.2574073 , 0.3921312 , 0.        , ..., 0.7907711 , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.2256733 , 0.2729268 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 1.6976906 , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0190174 , 0.        , 0.        , ..., 0.        , 0.05104918,\n",
       "        0.02766823],\n",
       "       [0.        , 0.01649332, 0.        , ..., 0.02229379, 0.        ,\n",
       "        0.        ],\n",
       "       [0.03422999, 0.01280672, 0.        , ..., 0.00662149, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.02113522, 0.00659116, 0.        , ..., 0.01329173, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.00338306, 0.00409143, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.03281737, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_feat = item['features'].astype('float32')\n",
    "att_feat = torch.FloatTensor(att_feat)\n",
    "att_feat = F.normalize(att_feat, dim=-1).numpy()\n",
    "att_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(item['bbox'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"train.h5\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "f['image_id'] = _image_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33854/33854 [1:02:41<00:00,  9.00it/s]\n"
     ]
    }
   ],
   "source": [
    "num_boxes = []\n",
    "wh = []\n",
    "bbox = []\n",
    "features = []\n",
    "objects = []\n",
    "with env.begin(write=False) as txn:\n",
    "    for index, image_id in tqdm(enumerate(_image_ids), total=len(_image_ids)):\n",
    "        item = pickle.loads(txn.get(image_id))\n",
    "        num_boxes.append(item['num_boxes'])\n",
    "        wh.append([(item['image_height'], item['image_width'])])\n",
    "        bbox.append(item['bbox'])\n",
    "        features.append(item['features'])\n",
    "        objects.append(item['objects'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "f['num_boxes'] = num_boxes\n",
    "f['wh'] = wh\n",
    "f['bbox'] = bbox\n",
    "f['features'] = features\n",
    "f['objects'] = objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"train.h5\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bbox', 'features', 'image_id', 'num_boxes', 'objects', 'wh']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33854"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f['bbox'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33854"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33854"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f['image_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33854"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f['wh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['feature_path', 'features', 'image_height', 'image_width', 'num_boxes', 'objects', 'cls_prob', 'bbox'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(\"/science/image/nlp-datasets/emanuele/checkpoints/M3P/checkpoint.pth\", map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'n_total_iter', 'best_metrics', 'best_stopping_criterion', 'model', 'model_optimizer', 'params'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt['model'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 28750)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt['epoch'], ckpt['n_total_iter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
